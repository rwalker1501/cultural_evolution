{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main and Target Module Overview\n",
    "\n",
    "This notebook gives an overview of logic flow, particularly of the main_module and a function in the target module. \n",
    "\n",
    "\n",
    "## 1.) main_module: MainProgram.generate_results\n",
    "\n",
    "This function generates results from a loaded set of targets. Mainly, it calls functions that:\n",
    "1. processes targets\n",
    "2. processes dataframe\n",
    "3. generates bins\n",
    "4. generates graphs and statitistics\n",
    "\n",
    "### Process Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustered_target_list, self.dataframe = tam.process_targets(self.base_path, population_data, original_target_list, self.dataframe, self.dataframe_loaded, self.clustering_on, self.date_window, self.critical_distance, directory, self.min_date_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process targets involves clustering targets (if clustering is on) and extracting the dataframe for these targets. This function is under the target_module.\n",
    "\n",
    "The dataframe contains the densities relevant to the clustered target list. In particular, it contains the sample densities for each target as well as their control/global densities. To do this, this dataframe has the following columns:\n",
    "\n",
    "- location: location of target\n",
    "- density\n",
    "- period\n",
    "- latlon_ind: index in the lat/lon lists\n",
    "- cluster_id\n",
    "- pseudo_type: for easy ordering in printing clustered list (puts samples first) such that sample (a) and control (b)\n",
    "- type: sample (s) or control (c)\n",
    "- contribution: for bins - to avoid double counting, contribution is 1/number_of_targets_in_cluster\n",
    "\n",
    "### Process Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_sample_means, all_control_means, growth_coefficients, samples_gt_controls, n_targets_gt_0, self.dataframe = stm.process_dataframe(self.dataframe, max_for_uninhabited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to process the dataframe through the process_dataframe function of the stats_module. This involves extracting statistics from the dataframe (means, growth coefficients, etc) and removing clusters which have 0 sample means. Note that the statistics are measured based on densities that are greater than max_for_uninhabited, but these densities are not removed from the dataframe. The function returns the following values:\n",
    "- all_sample_means\n",
    "- all_control_means\n",
    "- growth_coefficients\n",
    "- samples_gt_controls: number of sample means that are greater than control means\n",
    "- n_targets_gt_0: number of targets that have sample means greater than 0\n",
    "- dataframe: the new dataframe with filtered clusters\n",
    "\n",
    "### Generate bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_array, sample_counts, control_counts, multipliers, p_samples, p_controls = stm.generate_bin_values(self.dataframe, population_data, max_for_uninhabited)\n",
    "wrm.write_bin_table(f2, bin_array, sample_counts, control_counts, multipliers, p_samples, p_controls)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins are generated using the dataframe that has been processed. The generate_bin_values function from the stats_module is called in order to get the values for the bins. The bins are then written down in a file through the write_module's write_bin_table function. Note that bins start from 0.\n",
    "\n",
    "### Generate graphs and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generating graphs and statistics, there are three parts:\n",
    "\n",
    "1. Generate graphs and stats of likelihood ratios and sites\n",
    "2. Generate the graphs and statistics for p_samples and p_controls\n",
    "3. Plotting for growth coefficients and targets\n",
    "\n",
    "#### Graphs and stats for likelihood ratios and sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stm.generate_graphs_and_write_stats(bin_array, multipliers, sample_counts, control_counts, f2, new_path, self.minimum_multiplier, directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   For this part, we call a single function from the stats_module called <b>generate_graphs_and_write_stats</b>. This fits, plots, and writes the statistics for (linear and threshold) likelihood ratios and sites. The content of this function will be discussed later.\n",
    "    \n",
    "   It particularly gives the following output:\n",
    "       - a graph for the linear predicted likelihood ratio\n",
    "       - a graph for the threshold predicted likelihood ratio\n",
    "       - a graph for the linear predicted sites\n",
    "       - a graph for the threshold predicted sites\n",
    "       - writes the LMS for linear and threshold likelihood ratios\n",
    "       - writes the coefficients for the linear and threshold model\n",
    "       - writes the r2 score and chi score for linear and threshold\n",
    "       \n",
    "#### Graphs and stats for p_samples and p_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_binomial, threshold, threshold_success_count, threshold_trial_count, threshold_samples, threshold_controls = stm.get_p_threshold_and_binomial(p_samples, p_controls, bin_array)\n",
    "plm.plot_p_graphs(bin_array, p_samples, p_controls, threshold, directory, new_path)\n",
    "\n",
    "t_threshold_wilcoxon, p_threshold_wilcoxon = wilcoxon(threshold_controls, threshold_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the statistics concerning the threshold of p_samples and p_controls through the <b>get_p_threshold_and_binomial</b> of the <b>stats_module</b>. This function calculates the threshold that gives the smallest binomial of the p_samples and p_controls wherein p_sample <= p_control is considered a success. The function then returns the following:\n",
    "    - threshold binomial\n",
    "    - threshold\n",
    "    - threshold success count\n",
    "    - threshold trial count\n",
    "    - threshold samples\n",
    "    - threshold controls\n",
    "    \n",
    "The relevant threshold values are then plotted through the plot_p_graphs function of the plot_module. \n",
    "\n",
    "The threshold controls and threshold samples are then used to compute for the wilcoxon statistic.\n",
    "\n",
    "#### Plotting for growth coefficients and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - plots growth coefficients\n",
    "plm.plot_growth_coefficient_boxplot(growth_coefficients, new_path)\n",
    "\n",
    "# - plots targets and controls on a map\n",
    "plm.plot_targets_on_map(self.dataframe, self.controls_dataframe, new_path, directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call the plot_growth_coefficient_boxplot and plot_targets_on_map functions from the plot module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.) target_module.extract_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts the dataframe from a list of targets. This is called in target_module.process_targets after clustering targets, and it is only called if a processed target has not been loaded. \n",
    "\n",
    "To reiterate, a dataframe contains the relevant densities for a list of targets. To extract a dataframe, we have to check the densities in the population data against the latlons and time for each target. This involves having nexted loops checking latlons and time. How this function works will be explained in several main segments:\n",
    "\n",
    "1. create time dictionaries (important for step 3)\n",
    "2. loop through latlon indices\n",
    "    - loop through targets\n",
    "3. loop through time from date_from to date_to\n",
    "\n",
    "\n",
    "### Create time dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_dict, next_time_dict = create_time_dictionaries(time_np, time_multiplier, population_data.ascending_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns two dictionaries: time_dict and next_time_dict.\n",
    "\n",
    "<b>time_dict</b> is used to get the index in the time_array given some time. The key for time_dict is time, while the value is the index for that time in the time_array. On the other hand, <b>next_time_dict</b> is used to get the next time given some time. The key for next_time_dict is some time, while the value is the next time.\n",
    "\n",
    "For example, we have the following time array: <br>\n",
    "[0, 100, 200, 300, 400]\n",
    "\n",
    "Then: <br>\n",
    "time_dict[200] = 2 <br>\n",
    "next_time_dict[300] = 400 <br>\n",
    "next_time_dict[400] = -1\n",
    "\n",
    "These are used in order to loop through time given a start time to an end time.\n",
    "\n",
    "### Loop through latlon indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for latlon_ind in range(0, latlon_length):\n",
    "    if latlon_ind % 500 == 0:\n",
    "        print '.',        \n",
    "\n",
    "    densities_in_latlonind = den_np[:, latlon_ind]\n",
    "    sum_of_densities = np.nansum(densities_in_latlonind)      \n",
    "    if np.isnan(sum_of_densities) or sum_of_densities <= 0:\n",
    "        continue\n",
    "        \n",
    "    lat=lat_np[latlon_ind]\n",
    "    lon=lon_np[latlon_ind]\n",
    "\n",
    "    for cluster in target_list:\n",
    "        number_of_targets_in_cluster = len(cluster)\n",
    "        for target in cluster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer of our nested loop is a loop through each latitude and longitude, or latlon (these two arrays have the same length and correspond to each other. From here on we call them latlon). \n",
    "\n",
    "To reduce the time to extract dataframe, we skip the latlon_index where the densities through all the times of this latlon index is 0. \n",
    "\n",
    "For example, we have the following 2D density array where the columns corresponds to the latlon and the row corresponds to time: <br>\n",
    "0 0 0 1000 <br>\n",
    "0 0 2 0 <br>\n",
    "1 0 0 0 \n",
    "\n",
    "For this case, latlon_index 1 will be skipped since the sum for all densities in the column is 0. \n",
    "\n",
    "If the sum is not 0, we get the latitude and longitude. We then loop through each target in our target list, which is the third layer of our nested loops. \n",
    "\n",
    "### Loop through time from date_from to date_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_from = target.date_from + min_date_window\n",
    "date_to = target.date_from + date_window\n",
    "\n",
    "time = date_from\n",
    "if  date_from % time_multiplier != 0:\n",
    "    time = date_from + (time_multiplier - date_from % time_multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third layer of our nested loop is a loop through time. For each target, we loop through time from date_from to date_to. <b>date_from</b> is computed using the target's date_from plus the minimum date window, while <b>date_to</b> is computed using the sum of the target's date_from and the date_window.\n",
    "\n",
    "The starting time is then computed. The starting time should be the first time that exists in the time_array within the range of date_from and date_to. Since time is always a multiple of time_multiplier, we can check if the value of date_from exists using modulo time_multiplier. Otherwise, we get the next possible time through the equation: time = date_from + (time_multiplier - date_from % time_multiplier)\n",
    "\n",
    "Then, for each time and latlon, we check if the time and latlon are in the target's specification using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if in_target_location(target, time, lat, lon, is_control == 1, date_window):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When is_control = 1, we check if the latlon is within the globals of the target (densities within the time and longitude of the target). Otherwise, we check if the latlon is within the samples (densities within the time and latlon of the target).\n",
    "\n",
    "We also check if the density is greater than 0. If the latlon and time pass through these checks, then the values are appended to corresponding arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if density > 0:\n",
    "    latlon_inds.append(latlon_ind)\n",
    "    periods.append(time)\n",
    "    densities.append(density)\n",
    "    cluster_ids.append(target.cluster_id)\n",
    "    locations.append(target.location)\n",
    "    contributions.append(float(1)/number_of_targets_in_cluster)\n",
    "\n",
    "    if is_control == 0:\n",
    "        pseudo_types.append('a')\n",
    "        types.append('s')\n",
    "    else:\n",
    "        pseudo_types.append('b')\n",
    "        types.append('c')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
